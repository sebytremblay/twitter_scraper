{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Data locatiosn\n",
    "raw_data_path = \"./data/ticker_tweets.csv\"\n",
    "processed_data_path = raw_data_path.replace(\".csv\", \"_processed.csv\")\n",
    "tweet_col = \"Tweet\"\n",
    "data_size = -1\n",
    "\n",
    "# Model components\n",
    "output_dir = \"./gpu_output/v2/bert_models\"\n",
    "tokenizer_output_dir = f\"{output_dir}/tuned_tokenizer\"\n",
    "model_output_dir = f\"{output_dir}/tuned_model\"\n",
    "label_encoder_output_dir = f\"{output_dir}/label_encoder.pkl\"\n",
    "\n",
    "# Model parameters\n",
    "max_len = 256\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Model output names\n",
    "regex_output = \"Regex Symbol\"\n",
    "model_output = \"RoBERTA Symbol\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model & Data Loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from utils import data_cleaning as dc\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "raw_tweets = dc.init_df(False, raw_data_path, processed_data_path, 50, tweet_col)\n",
    "\n",
    "# Load the model, tokenizer, and label encoder\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_output_dir)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(tokenizer_output_dir)\n",
    "with open(label_encoder_output_dir, 'rb') as f:\n",
    "    label_encoder = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "from utils import tweet_identification as ti\n",
    "importlib.reload(ti)\n",
    "\n",
    "# Convert the tweets column to a list\n",
    "tweets = raw_tweets[tweet_col].tolist()\n",
    "\n",
    "# BERT Classification\n",
    "batch_size = 32\n",
    "predicted_labels = ti.classify_tweets(tweets, model, tokenizer, label_encoder, device, max_len, batch_size)\n",
    "raw_tweets[model_output] = predicted_labels\n",
    "\n",
    "# Regex Classification\n",
    "nyse_stocks = pd.read_csv(\"./data/nyse_stock_info.csv\")\n",
    "nyse_tickers = set(nyse_stocks[\"Symbol\"].str.upper())\n",
    "raw_tweets[regex_output] = raw_tweets[tweet_col].apply(lambda x: ti.get_ticker_strings(x, nyse_tickers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def are_anagrams(str1, str2):\n",
    "    return Counter(str1) == Counter(str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the DataFrame\n",
    "filtered_df = raw_tweets.copy()\n",
    "\n",
    "# Replace NA values with empty strings in 'BERT Symbol' and 'Regex Symbol'\n",
    "filtered_df[model_output] = filtered_df[model_output].fillna(\"\")\n",
    "filtered_df[regex_output] = filtered_df[regex_output].fillna(\"\")\n",
    "\n",
    "# Find all the tweets where the BERT and Regex labels are different\n",
    "filtered_df = filtered_df[~filtered_df.apply(lambda row: are_anagrams(row[model_output], row[regex_output]), axis=1)]\n",
    "display_cols = [tweet_col, regex_output, model_output]\n",
    "print(f\"Custom Model and Regex differed on {len(filtered_df)}/{len(raw_tweets)} tweets ({len(filtered_df) / len(raw_tweets)})%\")\n",
    "\n",
    "# Display classification differences\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(filtered_df[display_cols].head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class for test cases\n",
    "class CustomExample:\n",
    "    def __init__(self, msg, expected_answer):\n",
    "        self.msg = msg\n",
    "        self.expected_answer = expected_answer\n",
    "\n",
    "# Define custom test cases\n",
    "custom_tweets = [\n",
    "    CustomExample(\"I love my iPhone! I think Apple is a fantastic company.\", \n",
    "                  \"Apple\"),\n",
    "    CustomExample(\"The new iPad is amazing... I cannot wait to see what they do next year!\", \n",
    "                  \"Apple\"),\n",
    "    CustomExample(\"OpenAI is truly amazing. I use it almost every day for both work and school.\", \n",
    "                  \"Microsoft\"),\n",
    "    CustomExample(\"Semi-conductor companies are the stocks to watch in 2024. With the AI boom, their value is going through the roof!\", \n",
    "                  \"NVDA-INTC-AMD\")\n",
    "]\n",
    "\n",
    "# Output predictions\n",
    "custom_preds = ti.classify_tweets([tweet.msg for tweet in custom_tweets], \n",
    "                                  model, tokenizer, label_encoder, \n",
    "                                  device, max_len, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
