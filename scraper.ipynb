{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to scraping accounts\n",
    "!./utils/twscrape_login.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping parameters\n",
    "search_critieria = [\"$AMZN\", \"$AAPL\", \"$QQQ\", \"$NVDA\", \"$AMD\", \"$TSLA\"\n",
    "                    \"$GOOGL\", \"$MSFT\", \"$SPY\", \"$NFLX\",\n",
    "                    \"$FB\", \"$BABA\", \"$PYPL\", \"$INTC\", \"$MU\",\n",
    "                    \"$ADBE\", \"$AMAT\", \"$CSCO\", \"$IBM\", \"$QCOM\",\n",
    "                    \"$ORCL\", \"$CRM\", \"$TSM\", \"$TXN\", \"$ACN\",\n",
    "                    \"stock market\", \"stock market news\", \"stock market crash\",\n",
    "                    \"stock market today\", \"stock market live\", \"stock market futures\",\n",
    "                    \"stock market analysis\", \"stock market update\", \"stock market forecast\",\n",
    "                    \"stock market predictions\", \"stock market trends\", \"stock market data\"]\n",
    "\n",
    "# Data save locations\n",
    "base_output_dir = \"./data/scraping/06.15\"\n",
    "individual_dir = f\"{base_output_dir}/individual\"\n",
    "all_dir = f\"{base_output_dir}/raw_tweets.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Search Scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "from twscrape import API, gather\n",
    "from utils import scraping as sc\n",
    "importlib.reload(sc)\n",
    "\n",
    "# Defines how many Tweets to scrape per search query. Set to -1 to scrape all available data\n",
    "tweet_limit = -1\n",
    "\n",
    "# Conduct scrapinb\n",
    "api = API()\n",
    "tweets = []\n",
    "for search in search_critieria:\n",
    "    # Searches for tweets containing the search term since 2024\n",
    "    query = f\"{search} since:2024-05-01 lang:en min_faves:10\"\n",
    "    \n",
    "    # Gathers the results on all pages\n",
    "    query_results = []\n",
    "    query_results.extend(await gather(api.search(query, limit=tweet_limit, kv={\"product\": \"Top\"})))\n",
    "    query_results.extend(await gather(api.search(query, limit=tweet_limit, kv={\"product\": \"Latest\"})))\n",
    "\n",
    "    # Appends the results to the list of tweets\n",
    "    tweets.extend(query_results)\n",
    "    \n",
    "    # Saves the results to a file\n",
    "    file_name = search.replace(\"$\", \"\").replace(\" \", \"_\")\n",
    "    sc.save_tweets(query_results, search, f'{individual_dir}/RAW_TWEETS_{file_name}.csv')\n",
    "    \n",
    "# Saves all the tweets to a centralized file\n",
    "sc.save_tweets(tweets, \"all\", all_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
